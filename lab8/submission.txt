Nadeem Malik - Data Science Lab 8


===================== Storm: WordCountTopology.java
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.umd.assignment;

import backtype.storm.Config;
import backtype.storm.LocalCluster;
import backtype.storm.StormSubmitter;
import backtype.storm.task.ShellBolt;
import backtype.storm.topology.BasicOutputCollector;
import backtype.storm.topology.IRichBolt;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.TopologyBuilder;
import backtype.storm.topology.base.BaseBasicBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;

import org.umd.assignment.spout.RandomSentenceSpout;
import org.umd.assignment.spout.TwitterSampleSpout;

import java.util.HashSet;
import java.util.HashMap;
import java.util.PriorityQueue;
import java.util.ArrayList;
import java.util.Map;
import java.io.BufferedReader;
import java.io.FileReader;
import java.lang.Integer;





/**
 * This topology demonstrates Storm's stream groupings and multilang capabilities.
 */
public class WordCountTopology {
  public static class SplitSentence extends ShellBolt implements IRichBolt {

    public SplitSentence() {
      super("python", "splitsentence.py");
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
      declarer.declare(new Fields("word"));
    }

    @Override
    public Map<String, Object> getComponentConfiguration() {
      return null;
    }
  }

	public static class Word implements Comparable<Word>{
		public String text;
		public int count;
		public Word(String text, int count) {
			this.text = text;
			this.count = count;
		}

		public int compareTo(Word other) {
			return - ((Integer)count).compareTo(other.count);
		}
	}

  public static class WordCount extends BaseBasicBolt {
    Map<String, Integer> counts = new HashMap<String, Integer>();
    HashSet<String> stopWords = new HashSet<String>();

    public void setStopWords(HashSet<String> stopWords) {
    	this.stopWords = stopWords;
    }

    @Override
    public void execute(Tuple tuple, BasicOutputCollector collector) {
      
		// ----------------- Task 2	---------------------------------
		//
		//
		//	Modify this code to exclude stop-words from counting.
		//  Stopword list is provided in the lab folder. 
		//
		//
		// ---------------------------------------------------------


		String word = tuple.getString(0);
		if(!stopWords.contains(word)) {
			Integer count = counts.get(word);
			if (count == null)
				count = 0;
			count++;
			counts.put(word, count);
			collector.emit(new Values(word, count));
		}
    }

	@Override
	public void cleanup()
	{
		// ------------------------  Task 3 ---------------------------------------
		//
		//
		//	This function gets called when the Stream processing finishes.
		//	MODIFY this function to print the most frequent words that co-occur 
		//	with Obama [The TwitterSimpleSpout already gives you Tweets that contain
		//  the word obama].
		//
		//	Since multiple threads will be doing the same cleanup operation, writing the
		//	output to a file might not work as desired. One way to do this would be
		//  print the output (using System.out.println) and do a grep/awk/sed on that.
		//  For a simple example see inside the runStorm.sh.
		//
		//--------------------------------------------------------------------------
		
		// top 10 words co-occuring with Obama
		PriorityQueue<Word> pq = new PriorityQueue<Word>(10);

		for(String key : counts.keySet()) {
			pq.add(new Word(key, counts.get(key)));
		}

		for(int i = 1; i <= 10; i++) {
			Word w = pq.poll();
			System.out.println(w.text + " " + w.count);
		}
	}

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
      declarer.declare(new Fields("word", "count"));
    }
  }

  public static void main(String[] args) throws Exception {

    TopologyBuilder builder = new TopologyBuilder();

	// ---------------------------- Task 1 -------------------------------------
	//
	//		You need to use TwitterSampleSpout() for the assignemt. But, it won't work
	//		unless you set up the access token correctly in the TwitterSampleSpout.java
	//
	//		RandomSentenceSpout() simply spits out a random sentence. 
	//
	//--------------------------------------------------------------------------

	// Setting up a spout
    //builder.setSpout("spout", new RandomSentenceSpout(), 3);
    builder.setSpout("spout", new TwitterSampleSpout(), 3);

	// Setting up bolts
    builder.setBolt("split", new SplitSentence(), 3).shuffleGrouping("spout");

    // read in the stop words file
    HashSet<String> stopWords = new HashSet<String>();

    BufferedReader br = new BufferedReader(
    	new FileReader("/Users/nadeem/Desktop/Classes/datascience-fall14/lab8/Stopwords.txt"));
    String line;

    while((line = br.readLine()) != null) {
    	String word = line.trim();
    	stopWords.add(word);
    }


    WordCount wc = new WordCount();
    wc.setStopWords(stopWords);

    builder.setBolt("count", wc, 3).fieldsGrouping("split", new Fields("word"));

    Config conf = new Config();
    conf.setDebug(true);


    if (args != null && args.length > 0) {
      conf.setNumWorkers(3);

      StormSubmitter.submitTopologyWithProgressBar(args[0], conf, builder.createTopology());
    }
    else {
      conf.setMaxTaskParallelism(3);

      LocalCluster cluster = new LocalCluster();
      cluster.submitTopology("word-count", conf, builder.createTopology());

	  // --------------------------- Task 4 ---------------------------------
	  //
	  //	The sleep time simply indicates for how long you want to keep your
	  //	system up and running. 10000 (miliseconds) here means 10 seconds.
	  // 	
	  //
	  // ----------------------------------------------------------------------

      //Thread.sleep(10000);
      Thread.sleep(600000);

      cluster.shutdown(); // blot "cleanup" function is called when cluster is shutdown (only works in local mode)
    }
  }
}



===================== Storm: TwitterSampleSpout.java
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


//package org.umd.assignment.spout;

package org.umd.assignment.spout;

import java.util.Map;
import java.util.concurrent.LinkedBlockingQueue;

import twitter4j.FilterQuery;
import twitter4j.StallWarning;
import twitter4j.Status;
import twitter4j.StatusDeletionNotice;
import twitter4j.StatusListener;
import twitter4j.TwitterStream;
import twitter4j.TwitterStreamFactory;
import twitter4j.auth.AccessToken;
import twitter4j.conf.ConfigurationBuilder;

import backtype.storm.Config;
import backtype.storm.spout.SpoutOutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichSpout;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Values;
import backtype.storm.utils.Utils;

@SuppressWarnings("serial")
public class TwitterSampleSpout extends BaseRichSpout {

	SpoutOutputCollector _collector;
	LinkedBlockingQueue<String> queue = null;
	TwitterStream _twitterStream;
	String consumerKey;
	String consumerSecret;
	String accessToken;
	String accessTokenSecret;
	String[] keyWords;
	
	public TwitterSampleSpout(String consumerKey, String consumerSecret,
			String accessToken, String accessTokenSecret, String[] keyWords) {
		this.consumerKey = consumerKey;
		this.consumerSecret = consumerSecret;
		this.accessToken = accessToken;
		this.accessTokenSecret = accessTokenSecret;
		this.keyWords = keyWords;
	}


	//----------------------- Task 0 -----------------------------------------
	//
	//  Use the following link (for visual help) to create a Twitter App for yourselves. In summary,
	//	the steps are:
	//				(a) Go to apps.twitter.com
	//				(b) Create an App [Put any website as an URL]
	//				(c) Go to "keys and Access Token tab"
	//				(d) Create you access token
	//				(e) Copy over the ConsumerKey, consumerSecret, accesstoken, and accessTokenSecret
	//				in the TwitterSampleSpout()
	//
	//	https://dev.twitter.com/oauth/overview/application-owner-access-tokens
	//	
	//
	//
	//------------------------------------------------------------------------

	public TwitterSampleSpout() {		
		this.consumerKey = "khqi5CeFvEoCaZXA71E7yl2l3";
		this.consumerSecret = "V51l3yFxBGCP7abnjLpq4NgsvvuE4ooG9uhsxJ34sQje8ATkn4";
		this.accessToken = "1445455944-U59x2XkzRAGXMu5ts55Yp7XnqL0tDEwACapDpld";
		this.accessTokenSecret = "bKrlv9xrr95Lc3YUGq3S5c2MW7mzkQFiDaN3Zr1Lrrzp0";
		this.keyWords = new String[1];
		this.keyWords[0] = "obama"; /* Filters All Tweets with word Obama */
	}

	@Override
	public void open(Map conf, TopologyContext context,
			SpoutOutputCollector collector) {
		queue = new LinkedBlockingQueue<String>(1000);
		_collector = collector;

		StatusListener listener = new StatusListener() {

			@Override
			public void onStatus(Status status) {
			
				queue.offer(status.getText());
			}

			@Override
			public void onDeletionNotice(StatusDeletionNotice sdn) {
			}

			@Override
			public void onTrackLimitationNotice(int i) {
			}

			@Override
			public void onScrubGeo(long l, long l1) {
			}

			@Override
			public void onException(Exception ex) {
			}

			@Override
			public void onStallWarning(StallWarning arg0) {
				// TODO Auto-generated method stub

			}

		};

		TwitterStream twitterStream = new TwitterStreamFactory(
				new ConfigurationBuilder().setJSONStoreEnabled(true).build())
				.getInstance();

		twitterStream.addListener(listener);
		twitterStream.setOAuthConsumer(consumerKey, consumerSecret);
		AccessToken token = new AccessToken(accessToken, accessTokenSecret);
		twitterStream.setOAuthAccessToken(token);
		
		if (keyWords.length == 0) {

			twitterStream.sample();
		}

		else {

			FilterQuery query = new FilterQuery().track(keyWords);
			twitterStream.filter(query);
		}

	}

	@Override
	public void nextTuple() {
		String ret = queue.poll();
		if (ret == null) {
			Utils.sleep(50);
		} else {
		     
			_collector.emit(new Values(ret));

		}
	}

	@Override
	public void close() {
		_twitterStream.shutdown();
	}

	@Override
	public Map<String, Object> getComponentConfiguration() {
		Config ret = new Config();
		ret.setMaxTaskParallelism(1);
		return ret;
	}

	@Override
	public void ack(Object id) {
	}

	@Override
	public void fail(Object id) {
	}

	@Override
	public void declareOutputFields(OutputFieldsDeclarer declarer) {
		declarer.declare(new Fields("tweet"));
	}

}


===================== Storm: Execution Output for a Sample Run

RT 2975
immigration 615
que 382
por 380
?President 360
Barack 303
I 302
plan 285
The 284
en 284


===================== Spark: Assignment.java


/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import scala.Tuple2;
import com.google.common.collect.Lists;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import java.util.ArrayList;
import java.util.regex.Pattern;

public final class Assignment {
    private static final Pattern SPACE = Pattern.compile(" ");

    public static void main(String[] args) {

        // Create the context with a 10 second batch size
        SparkConf sparkConf = new SparkConf().setAppName("Assignment");
        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf,  new Duration(10000));

        // Create a JavaReceiverInputDStream on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        // Note that no duplication in storage level only for running locally.
        // Replication necessary in distributed scenario for fault tolerance.
        JavaReceiverInputDStream<String> lines = ssc.socketTextStream(
                "localhost", Integer.parseInt("9999"), StorageLevels.MEMORY_AND_DISK_SER);

        JavaDStream<String> words = lines.flatMap(new FlatMapFunction<String, String>() {
                @Override

                public Iterable<String> call(String x) {
                    String[] l = SPACE.split(x);
                    ArrayList<String> obamaList = new ArrayList<String>();
                    for(String w1 : l) {
                        if(w1.toLowerCase().equals("#obama")) {
                            obamaList.add("#Obama");
                        }
                    }

                    return obamaList;
                }
                });

        // Reduce function adding two integers, defined separately for clarity
        Function2<Integer, Integer, Integer> reduceFunc = new Function2<Integer, Integer, Integer>() {
          @Override public Integer call(Integer i1, Integer i2) throws Exception {
            return i1 + i2;
          }
        };


        JavaPairDStream<String, Integer> wordCounts = words.mapToPair(
                new PairFunction<String, String, Integer>() {
                @Override
                public Tuple2<String, Integer> call(String s) {
                    return new Tuple2<String, Integer>(s, 1);
                }
                }).reduceByKeyAndWindow(reduceFunc, new Duration(30000), new Duration(10000));

        wordCounts.print();

        ssc.start();

        ssc.awaitTermination();
    }
}


===================== Spark: Execution Output for a Sample Run

-------------------------------------------
Time: 1416697150000 ms
-------------------------------------------
(#Obama,6)

-------------------------------------------
Time: 1416697160000 ms
-------------------------------------------
(#Obama,7)

-------------------------------------------
Time: 1416697170000 ms
-------------------------------------------
(#Obama,9)

-------------------------------------------
Time: 1416697180000 ms
-------------------------------------------
(#Obama,6)

-------------------------------------------
Time: 1416697190000 ms
-------------------------------------------
(#Obama,5)

-------------------------------------------
Time: 1416697200000 ms
-------------------------------------------
(#Obama,3)

-------------------------------------------
Time: 1416697210000 ms
-------------------------------------------
(#Obama,1)

-------------------------------------------
Time: 1416697220000 ms
-------------------------------------------
(#Obama,5)

-------------------------------------------
Time: 1416697230000 ms
-------------------------------------------
(#Obama,11)



